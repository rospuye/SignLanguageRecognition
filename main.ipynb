{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project 1: American Sign Language Understanding\n",
    "A project for the course of Autonomous Learning at the University of Aveiro, 2022/2023. This project was developed by Diogo Monteiro (NMec 97606) and Isabel Ros√°rio (NMec 93343). This approach attemps to build a neural network that understands American sign language.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images in dataset: 27455\n",
      "Shape of each image: (28, 28)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'First image of the dataset')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = pd.read_csv('data/sign_mnist_train.csv') #, header=0)\n",
    "\n",
    "# get number of images in the dataset (should be 27,455)\n",
    "num_images = data.shape[0]\n",
    "print('Number of images in dataset:', num_images)\n",
    "\n",
    "# single out and analyse first image\n",
    "first_image = data.iloc[0, 1:].values # get first image of the dataset\n",
    "first_image = first_image.reshape(28, 28).astype('uint8') # reshape it to a 28x28 matrix\n",
    "print('Shape of each image:', first_image.shape)\n",
    "\n",
    "# show first image\n",
    "plt.imshow(first_image, cmap='gray')\n",
    "plt.title('First image of the dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize pixel information (0-255 to 0-1)\n",
    "data.iloc[:, 1:] = data.iloc[:, 1:] / 255\n",
    "X, y = data.iloc[:, 1:].values, data.iloc[:, 0].values"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural network code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "\n",
    "    def __init__(self, n_inputs, n_neurons):\n",
    "        self.weights = 0.01 * np.random.randn(n_inputs, n_neurons)\n",
    "        self.biases = np.zeros((1, n_neurons))\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        self.inputs = inputs\n",
    "        self.output = np.dot(inputs, self.weights) + self.biases\n",
    "\n",
    "    def backwards(self, dvalues):\n",
    "        self.dweights = np.dot(self.inputs.T, dvalues) # dL/dW = dL/dY * dY/dW\n",
    "        self.dbiases = np.sum(dvalues, axis=0, keepdims=True)\n",
    "        self.dinputs = np.dot(dvalues, self.weights.T)\n",
    "\n",
    "class Activation:\n",
    "\n",
    "    def forward_ReLU(self, inputs):\n",
    "        self.inputs = inputs\n",
    "        self.output = np.maximum(0, inputs)\n",
    "\n",
    "    def backwards_ReLU(self, dvalues):\n",
    "        self.dinputs = dvalues.copy()\n",
    "        self.dinputs[self.inputs <= 0] = 0\n",
    "\n",
    "    def forward_Softmax(self, inputs):\n",
    "        exp_values = np.exp(inputs - np.max(inputs, axis=1, keepdims=True))\n",
    "        probabilities = exp_values / np.sum(exp_values, axis=1, keepdims=True)\n",
    "        self.output = probabilities\n",
    "\n",
    "    def backwards_Softmax(self, dvalues):\n",
    "        self.dinputs = np.empty_like(dvalues)\n",
    "        for index, (single_output, single_dvalues) in enumerate(zip(self.output, dvalues)):\n",
    "            single_output = single_output.reshape(-1, 1)\n",
    "            jacobian_matrix = np.diagflat(single_output) - np.dot(single_output, single_output.T)\n",
    "            self.dinputs[index] = np.dot(jacobian_matrix, single_dvalues)\n",
    "\n",
    "class Loss: # categorical cross-entropy\n",
    "    def calculate(self, output, y):\n",
    "        sample_losses = self.forward(output, y)\n",
    "        data_loss = np.mean(sample_losses)\n",
    "        return data_loss\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        samples = len(y_pred)\n",
    "        y_pred_clipped = np.clip(y_pred, 1e-7, 1 - 1e-7)\n",
    "        if len(y_true.shape) == 1:\n",
    "            correct_confidences = y_pred_clipped[range(samples), y_true]\n",
    "        elif len(y_true.shape) == 2:\n",
    "            correct_confidences = np.sum(y_pred_clipped * y_true, axis=1)\n",
    "        negative_log_likelihoods = -np.log(correct_confidences)\n",
    "        return negative_log_likelihoods\n",
    "    \n",
    "    def backward(self, dvalues, y_true):\n",
    "        samples = len(dvalues)\n",
    "        labels = len(dvalues[0])\n",
    "        if len(y_true.shape) == 1:\n",
    "            y_true = np.eye(labels)[y_true]\n",
    "        self.dinputs = -y_true / dvalues\n",
    "        self.dinputs = self.dinputs / samples\n",
    "\n",
    "class LossActivation: # combined softmax activation and cross-entropy loss for faster backward step\n",
    "    def __init__(self):\n",
    "        self.activation = Activation()\n",
    "        self.loss = Loss()\n",
    "\n",
    "    def forward(self, inputs, y_true):\n",
    "        self.activation.forward_Softmax(inputs)\n",
    "        self.output = self.activation.output\n",
    "        return self.loss.calculate(self.output, y_true)\n",
    "\n",
    "    def backward(self, dvalues, y_true):\n",
    "        samples = len(dvalues)\n",
    "        if len(y_true.shape) == 2:\n",
    "            y_true = np.argmax(y_true, axis=1)\n",
    "        self.dinputs = dvalues.copy()\n",
    "        self.dinputs[range(samples), y_true] -= 1\n",
    "        self.dinputs = self.dinputs / samples\n",
    "\n",
    "class Optimizer: # stochastic gradient descent\n",
    "    def __init__(self, learning_rate=1., decay=0., momentum=0.):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.current_learning_rate = learning_rate\n",
    "        self.decay = decay\n",
    "        self.iterations = 0\n",
    "        self.momentum = momentum\n",
    "    \n",
    "    def pre_update_params(self):\n",
    "        if self.decay:\n",
    "            self.current_learning_rate = self.learning_rate * (1. / (1. + self.decay * self.iterations))\n",
    "    \n",
    "    def update_params(self, layer):\n",
    "        if self.momentum:\n",
    "            if not hasattr(layer, 'weight_momentums'):\n",
    "                layer.weight_momentums = np.zeros_like(layer.weights)\n",
    "                layer.bias_momentums = np.zeros_like(layer.biases)\n",
    "            weight_updates = self.momentum * layer.weight_momentums - self.current_learning_rate * layer.dweights\n",
    "            layer.weight_momentums = weight_updates\n",
    "            bias_updates = self.momentum * layer.bias_momentums - self.current_learning_rate * layer.dbiases\n",
    "            layer.bias_momentums = bias_updates\n",
    "        else:\n",
    "            weight_updates = -self.current_learning_rate * layer.dweights\n",
    "            bias_updates = -self.current_learning_rate * layer.dbiases\n",
    "        layer.weights += weight_updates\n",
    "        layer.biases += bias_updates\n",
    "\n",
    "    def post_update_params(self):\n",
    "        self.iterations += 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, acc: 0.038, loss: 3.257, lr: 0.05\n",
      "epoch: 100, acc: 0.052, loss: 3.159, lr: 0.04999752512250644\n",
      "epoch: 200, acc: 0.145, loss: 3.066, lr: 0.04999502549496326\n",
      "epoch: 300, acc: 0.223, loss: 2.803, lr: 0.049992526117345455\n",
      "epoch: 400, acc: 0.303, loss: 2.488, lr: 0.04999002698961558\n",
      "epoch: 500, acc: 0.358, loss: 2.214, lr: 0.049987528111736124\n",
      "epoch: 600, acc: 0.425, loss: 2.002, lr: 0.049985029483669646\n",
      "epoch: 700, acc: 0.479, loss: 1.832, lr: 0.049982531105378675\n",
      "epoch: 800, acc: 0.523, loss: 1.688, lr: 0.04998003297682575\n",
      "epoch: 900, acc: 0.551, loss: 1.571, lr: 0.049977535097973466\n",
      "epoch: 1000, acc: 0.568, loss: 1.490, lr: 0.049975037468784345\n",
      "epoch: 1100, acc: 0.591, loss: 1.399, lr: 0.049972540089220974\n",
      "epoch: 1200, acc: 0.613, loss: 1.316, lr: 0.04997004295924593\n",
      "epoch: 1300, acc: 0.628, loss: 1.248, lr: 0.04996754607882181\n",
      "epoch: 1400, acc: 0.643, loss: 1.189, lr: 0.049965049447911185\n",
      "epoch: 1500, acc: 0.652, loss: 1.161, lr: 0.04996255306647668\n",
      "epoch: 1600, acc: 0.671, loss: 1.101, lr: 0.049960056934480884\n",
      "epoch: 1700, acc: 0.694, loss: 1.028, lr: 0.04995756105188642\n",
      "epoch: 1800, acc: 0.712, loss: 0.986, lr: 0.049955065418655915\n",
      "epoch: 1900, acc: 0.674, loss: 1.065, lr: 0.04995257003475201\n",
      "epoch: 2000, acc: 0.713, loss: 0.938, lr: 0.04995007490013731\n",
      "epoch: 2100, acc: 0.724, loss: 0.935, lr: 0.0499475800147745\n",
      "epoch: 2200, acc: 0.732, loss: 0.904, lr: 0.0499450853786262\n",
      "epoch: 2300, acc: 0.746, loss: 0.855, lr: 0.0499425909916551\n",
      "epoch: 2400, acc: 0.758, loss: 0.821, lr: 0.04994009685382384\n",
      "epoch: 2500, acc: 0.778, loss: 0.760, lr: 0.04993760296509512\n",
      "epoch: 2600, acc: 0.703, loss: 0.924, lr: 0.049935109325431604\n",
      "epoch: 2700, acc: 0.807, loss: 0.698, lr: 0.049932615934796004\n",
      "epoch: 2800, acc: 0.798, loss: 0.695, lr: 0.04993012279315098\n",
      "epoch: 2900, acc: 0.821, loss: 0.656, lr: 0.049927629900459285\n",
      "epoch: 3000, acc: 0.824, loss: 0.632, lr: 0.049925137256683606\n",
      "epoch: 3100, acc: 0.813, loss: 0.653, lr: 0.04992264486178666\n",
      "epoch: 3200, acc: 0.775, loss: 0.699, lr: 0.04992015271573119\n",
      "epoch: 3300, acc: 0.822, loss: 0.623, lr: 0.04991766081847992\n",
      "epoch: 3400, acc: 0.821, loss: 0.611, lr: 0.049915169169995596\n",
      "epoch: 3500, acc: 0.829, loss: 0.607, lr: 0.049912677770240964\n",
      "epoch: 3600, acc: 0.701, loss: 0.982, lr: 0.049910186619178794\n",
      "epoch: 3700, acc: 0.839, loss: 0.545, lr: 0.04990769571677183\n",
      "epoch: 3800, acc: 0.864, loss: 0.504, lr: 0.04990520506298287\n",
      "epoch: 3900, acc: 0.860, loss: 0.509, lr: 0.04990271465777467\n",
      "epoch: 4000, acc: 0.861, loss: 0.516, lr: 0.049900224501110035\n",
      "epoch: 4100, acc: 0.890, loss: 0.449, lr: 0.04989773459295174\n",
      "epoch: 4200, acc: 0.853, loss: 0.488, lr: 0.04989524493326262\n",
      "epoch: 4300, acc: 0.879, loss: 0.440, lr: 0.04989275552200545\n",
      "epoch: 4400, acc: 0.890, loss: 0.420, lr: 0.04989026635914307\n",
      "epoch: 4500, acc: 0.877, loss: 0.451, lr: 0.04988777744463829\n",
      "epoch: 4600, acc: 0.866, loss: 0.443, lr: 0.049885288778453954\n",
      "epoch: 4700, acc: 0.887, loss: 0.397, lr: 0.049882800360552884\n",
      "epoch: 4800, acc: 0.876, loss: 0.444, lr: 0.04988031219089794\n",
      "epoch: 4900, acc: 0.896, loss: 0.390, lr: 0.049877824269451976\n",
      "epoch: 5000, acc: 0.907, loss: 0.375, lr: 0.04987533659617785\n",
      "epoch: 5100, acc: 0.886, loss: 0.391, lr: 0.04987284917103844\n",
      "epoch: 5200, acc: 0.930, loss: 0.325, lr: 0.04987036199399661\n",
      "epoch: 5300, acc: 0.909, loss: 0.347, lr: 0.04986787506501525\n",
      "epoch: 5400, acc: 0.921, loss: 0.322, lr: 0.04986538838405724\n",
      "epoch: 5500, acc: 0.946, loss: 0.286, lr: 0.049862901951085496\n",
      "epoch: 5600, acc: 0.948, loss: 0.269, lr: 0.049860415766062906\n",
      "epoch: 5700, acc: 0.935, loss: 0.286, lr: 0.0498579298289524\n",
      "epoch: 5800, acc: 0.953, loss: 0.259, lr: 0.04985544413971689\n",
      "epoch: 5900, acc: 0.939, loss: 0.266, lr: 0.049852958698319315\n",
      "epoch: 6000, acc: 0.943, loss: 0.268, lr: 0.04985047350472258\n",
      "epoch: 6100, acc: 0.960, loss: 0.238, lr: 0.04984798855888967\n",
      "epoch: 6200, acc: 0.843, loss: 0.440, lr: 0.049845503860783506\n",
      "epoch: 6300, acc: 0.918, loss: 0.327, lr: 0.049843019410367055\n",
      "epoch: 6400, acc: 0.951, loss: 0.259, lr: 0.04984053520760327\n",
      "epoch: 6500, acc: 0.947, loss: 0.257, lr: 0.049838051252455155\n",
      "epoch: 6600, acc: 0.960, loss: 0.233, lr: 0.049835567544885655\n",
      "epoch: 6700, acc: 0.958, loss: 0.229, lr: 0.04983308408485778\n",
      "epoch: 6800, acc: 0.965, loss: 0.215, lr: 0.0498306008723345\n",
      "epoch: 6900, acc: 0.962, loss: 0.216, lr: 0.04982811790727884\n",
      "epoch: 7000, acc: 0.969, loss: 0.202, lr: 0.04982563518965381\n",
      "epoch: 7100, acc: 0.968, loss: 0.197, lr: 0.049823152719422406\n",
      "epoch: 7200, acc: 0.935, loss: 0.262, lr: 0.049820670496547675\n",
      "epoch: 7300, acc: 0.980, loss: 0.176, lr: 0.04981818852099264\n",
      "epoch: 7400, acc: 0.979, loss: 0.173, lr: 0.049815706792720335\n",
      "epoch: 7500, acc: 0.976, loss: 0.174, lr: 0.0498132253116938\n",
      "epoch: 7600, acc: 0.938, loss: 0.246, lr: 0.04981074407787611\n",
      "epoch: 7700, acc: 0.985, loss: 0.155, lr: 0.049808263091230306\n",
      "epoch: 7800, acc: 0.979, loss: 0.159, lr: 0.04980578235171948\n",
      "epoch: 7900, acc: 0.985, loss: 0.149, lr: 0.04980330185930667\n",
      "epoch: 8000, acc: 0.989, loss: 0.141, lr: 0.04980082161395499\n",
      "epoch: 8100, acc: 0.943, loss: 0.235, lr: 0.04979834161562752\n",
      "epoch: 8200, acc: 0.980, loss: 0.145, lr: 0.04979586186428736\n",
      "epoch: 8300, acc: 0.989, loss: 0.132, lr: 0.04979338235989761\n",
      "epoch: 8400, acc: 0.991, loss: 0.127, lr: 0.04979090310242139\n",
      "epoch: 8500, acc: 0.992, loss: 0.124, lr: 0.049788424091821805\n",
      "epoch: 8600, acc: 0.993, loss: 0.120, lr: 0.049785945328062006\n",
      "epoch: 8700, acc: 0.993, loss: 0.118, lr: 0.0497834668111051\n",
      "epoch: 8800, acc: 0.991, loss: 0.118, lr: 0.049780988540914256\n",
      "epoch: 8900, acc: 0.991, loss: 0.116, lr: 0.0497785105174526\n",
      "epoch: 9000, acc: 0.995, loss: 0.108, lr: 0.04977603274068329\n",
      "epoch: 9100, acc: 0.996, loss: 0.105, lr: 0.04977355521056952\n",
      "epoch: 9200, acc: 0.997, loss: 0.102, lr: 0.049771077927074414\n",
      "epoch: 9300, acc: 0.997, loss: 0.099, lr: 0.0497686008901612\n",
      "epoch: 9400, acc: 0.997, loss: 0.097, lr: 0.04976612409979302\n",
      "epoch: 9500, acc: 0.998, loss: 0.095, lr: 0.0497636475559331\n",
      "epoch: 9600, acc: 0.998, loss: 0.092, lr: 0.049761171258544616\n",
      "epoch: 9700, acc: 0.998, loss: 0.090, lr: 0.0497586952075908\n",
      "epoch: 9800, acc: 0.999, loss: 0.088, lr: 0.04975621940303483\n",
      "epoch: 9900, acc: 0.999, loss: 0.086, lr: 0.049753743844839965\n",
      "epoch: 10000, acc: 0.999, loss: 0.084, lr: 0.04975126853296942\n"
     ]
    }
   ],
   "source": [
    "num_features = X.shape[1]\n",
    "size_layer1 = 100\n",
    "size_layer2 = 26\n",
    "\n",
    "activation = Activation()\n",
    "layer1 = Layer(num_features, size_layer1)\n",
    "layer2 = Layer(size_layer1, size_layer2)\n",
    "loss_activation = LossActivation()\n",
    "optimizer = Optimizer(learning_rate=0.05, decay=5e-7)\n",
    "\n",
    "for epoch in range(10001):\n",
    "    layer1.forward(X)\n",
    "    activation.forward_ReLU(layer1.output)\n",
    "\n",
    "    layer2.forward(layer1.output)\n",
    "    loss = loss_activation.forward(layer2.output, y)\n",
    "\n",
    "    predictions = np.argmax(loss_activation.output, axis=1)\n",
    "    if len(y.shape) == 2:\n",
    "        y = np.argmax(y, axis=1)\n",
    "    accuracy = np.mean(predictions == y)\n",
    "\n",
    "    if not epoch % 100:\n",
    "        print(f'epoch: {epoch}, ' + f'acc: {accuracy:.3f}, ' + f'loss: {loss:.3f}, ' + f'lr: {optimizer.current_learning_rate}')\n",
    "    \n",
    "    # backward pass\n",
    "    loss_activation.backward(loss_activation.output, y)\n",
    "    layer2.backwards(loss_activation.dinputs)\n",
    "    activation.backwards_ReLU(layer2.dinputs)\n",
    "    layer1.backwards(layer2.dinputs)\n",
    "\n",
    "    # update weights and biases\n",
    "    optimizer.pre_update_params()\n",
    "    optimizer.update_params(layer1)\n",
    "    optimizer.update_params(layer2)\n",
    "    optimizer.post_update_params()\n",
    "\n",
    "# layer1.forward(X)\n",
    "# activation.forward_ReLU(layer1.output)\n",
    "# layer2.forward(layer1.output)\n",
    "\n",
    "# loss = loss_activation.forward(layer2.output, y)\n",
    "# # print(loss_activation.output[:5])\n",
    "# print('Loss:', loss)\n",
    "\n",
    "# predictions = np.argmax(loss_activation.output, axis=1)\n",
    "# if len(y.shape) == 2:\n",
    "#     y = np.argmax(y, axis=1)\n",
    "# accuracy = np.mean(predictions == y)\n",
    "\n",
    "# print('Accuracy:', accuracy)\n",
    "\n",
    "# # backpropagation\n",
    "# loss_activation.backward(loss_activation.output, y)\n",
    "# layer2.backwards(loss_activation.dinputs)\n",
    "# activation.backwards_ReLU(layer2.dinputs)\n",
    "# layer1.backwards(layer2.dinputs)\n",
    "\n",
    "# # print(layer1.dweights)\n",
    "# # print(layer1.dbiases)\n",
    "# # print(layer2.dweights)\n",
    "# # print(layer2.dbiases)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a5a87ee616be0254e3f1af9223138e3faeac65b2c9d91bc22a9fc5a4a8bd8eb0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
